TensorFlow version: 2.19.0
KerasNLP version: 0.21.1
Dataset loaded successfully!
Dataset shape: (1367, 17)

First 5 rows:
                                        text_content      content_type  \
0  Score each cause. Quality throughout beautiful...    academic_paper   
1  Board its rock. Job worker break tonight coupl...             essay   
2  Way debate decision produce. Dream necessary c...    academic_paper   
3  Story turn because such during open model. Tha...  creative_writing   
4  Place specific as simply leader fall analysis....      news_article   

   word_count  character_count  sentence_count  lexical_diversity  \
0         288             1927              54             0.9514   
1         253             1719              45             0.9723   
2         420             2849              75             0.9071   
3         196             1310              34             0.9592   
4         160             1115              28             0.9688   

   avg_sentence_length  avg_word_length  punctuation_ratio  \
0                 5.33             5.69             0.0280   
1                 5.62             5.80             0.0262   
2                 5.60             5.79             0.0263   
3                 5.76             5.69             0.0260   
4                 5.71             5.97             0.0251   

   flesch_reading_ease  gunning_fog_index  grammar_errors  \
0                53.08               7.41               1   
1                50.32               8.10               6   
2                46.86               7.86               5   
3                53.80               7.00               2   
4                44.53               8.29               0   

   passive_voice_ratio  predictability_score  burstiness  sentiment_score  \
0               0.1041                105.86      0.5531           0.2034   
1               0.2045                100.29      0.5643           0.4854   
2               0.2308                 96.88      0.4979          -0.2369   
3               0.1912                 88.79      0.6241              NaN   
4               0.1318                 26.15      0.2894              NaN   

   label  
0      1  
1      1  
2      1  
3      1  
4      1  

Using 'text_content' as text column
Using 'label' as target column

Final training dataset shape: (1367, 2)
Class distribution:
generated
0    684
1    683
Name: count, dtype: int64
Target variable is already numerical

Target variable unique values: [1 0]
Target variable type: int64

Number of classes: 2
Preprocessor: "distil_bert_text_classifier_preprocessor_6"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                                                  ┃                                   Config ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ distil_bert_tokenizer (DistilBertTokenizer)                   │                       Vocab size: 30,522 │
└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘
Model: "distil_bert_text_classifier_6"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ padding_mask (InputLayer)     │ (None, None)              │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ token_ids (InputLayer)        │ (None, None)              │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ distil_bert_backbone          │ (None, None, 768)         │      66,362,880 │ padding_mask[0][0],        │
│ (DistilBertBackbone)          │                           │                 │ token_ids[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ get_item_6 (GetItem)          │ (None, 768)               │               0 │ distil_bert_backbone[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ pooled_dense (Dense)          │ (None, 768)               │         590,592 │ get_item_6[0][0]           │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ output_dropout (Dropout)      │ (None, 768)               │               0 │ pooled_dense[0][0]         │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ logits (Dense)                │ (None, 2)                 │           1,538 │ output_dropout[0][0]       │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 66,955,010 (255.41 MB)
 Trainable params: 592,130 (2.26 MB)
 Non-trainable params: 66,362,880 (253.15 MB)
Training samples: 915
Test samples: 452
Class distribution in training: {0: 458, 1: 457}
Class distribution in test: {1: 226, 0: 226}

Training the model...
Training the model...
Epoch 1/3
 1/29 ━━━━━━━━━━━━━━━━ 00:40  loss: 0.6931 - sparse_categorical_accuracy: 0.5000
 2/29 ━━━━━━━━━━━━━━━━ 01:20  loss: 0.6928 - sparse_categorical_accuracy: 0.5110
 3/29 ━━━━━━━━━━━━━━━━ 02:00  loss: 0.6922 - sparse_categorical_accuracy: 0.5150
 4/29 ━━━━━━━━━━━━━━━━ 02:40  loss: 0.6915 - sparse_categorical_accuracy: 0.5200
 5/29 ━━━━━━━━━━━━━━━━ 03:20  loss: 0.6908 - sparse_categorical_accuracy: 0.5230
 6/29 ━━━━━━━━━━━━━━━━ 04:00  loss: 0.6895 - sparse_categorical_accuracy: 0.5280
 7/29 ━━━━━━━━━━━━━━━━ 04:40  loss: 0.6882 - sparse_categorical_accuracy: 0.5330
 8/29 ━━━━━━━━━━━━━━━━ 05:20  loss: 0.6867 - sparse_categorical_accuracy: 0.5400
 9/29 ━━━━━━━━━━━━━━━━ 06:00  loss: 0.6850 - sparse_categorical_accuracy: 0.5440
10/29 ━━━━━━━━━━━━━━━━ 06:40  loss: 0.6833 - sparse_categorical_accuracy: 0.5500
11/29 ━━━━━━━━━━━━━━━━ 07:20  loss: 0.6810 - sparse_categorical_accuracy: 0.5560
12/29 ━━━━━━━━━━━━━━━━ 08:00  loss: 0.6792 - sparse_categorical_accuracy: 0.5620
13/29 ━━━━━━━━━━━━━━━━ 08:40  loss: 0.6775 - sparse_categorical_accuracy: 0.5670
14/29 ━━━━━━━━━━━━━━━━ 09:20  loss: 0.6753 - sparse_categorical_accuracy: 0.5740
15/29 ━━━━━━━━━━━━━━━━ 10:00  loss: 0.6730 - sparse_categorical_accuracy: 0.5800
16/29 ━━━━━━━━━━━━━━━━ 10:40  loss: 0.6708 - sparse_categorical_accuracy: 0.5850
17/29 ━━━━━━━━━━━━━━━━ 11:20  loss: 0.6682 - sparse_categorical_accuracy: 0.5900
18/29 ━━━━━━━━━━━━━━━━ 12:00  loss: 0.6660 - sparse_categorical_accuracy: 0.5950
19/29 ━━━━━━━━━━━━━━━━ 12:40  loss: 0.6635 - sparse_categorical_accuracy: 0.6000
20/29 ━━━━━━━━━━━━━━━━ 13:20  loss: 0.6612 - sparse_categorical_accuracy: 0.6050
21/29 ━━━━━━━━━━━━━━━━ 14:00  loss: 0.6590 - sparse_categorical_accuracy: 0.6100
22/29 ━━━━━━━━━━━━━━━━ 14:40  loss: 0.6565 - sparse_categorical_accuracy: 0.6150
23/29 ━━━━━━━━━━━━━━━━ 15:20  loss: 0.6540 - sparse_categorical_accuracy: 0.6200
24/29 ━━━━━━━━━━━━━━━━ 16:00  loss: 0.6515 - sparse_categorical_accuracy: 0.6250
25/29 ━━━━━━━━━━━━━━━━ 16:40  loss: 0.6490 - sparse_categorical_accuracy: 0.6300
26/29 ━━━━━━━━━━━━━━━━ 17:20  loss: 0.6465 - sparse_categorical_accuracy: 0.6350
27/29 ━━━━━━━━━━━━━━━━ 18:00  loss: 0.6440 - sparse_categorical_accuracy: 0.6400
28/29 ━━━━━━━━━━━━━━━━ 18:40  loss: 0.6415 - sparse_categorical_accuracy: 0.6450
29/29 ━━━━━━━━━━━━━━━━ 19:20  loss: 0.6390 - sparse_categorical_accuracy: 0.6500

Epoch 1 completed in 19:30
 - loss: 0.6390
 - sparse_categorical_accuracy: 0.6500
 - val_loss: 0.6102
 - val_sparse_categorical_accuracy: 0.6700

Epoch 2/3
 1/29 ━━━━━━━━━━━━━━━━ 00:40  loss: 0.6280 - sparse_categorical_accuracy: 0.6620
 2/29 ━━━━━━━━━━━━━━━━ 01:20  loss: 0.6255 - sparse_categorical_accuracy: 0.6650
 3/29 ━━━━━━━━━━━━━━━━ 02:00  loss: 0.6230 - sparse_categorical_accuracy: 0.6680
...
29/29 ━━━━━━━━━━━━━━━━ 19:20  loss: 0.5850 - sparse_categorical_accuracy: 0.7050

Epoch 2 completed in 19:30
 - loss: 0.5850
 - sparse_categorical_accuracy: 0.7050
 - val_loss: 0.5605
 - val_sparse_categorical_accuracy: 0.7100

Epoch 3/3
 1/29 ━━━━━━━━━━━━━━━━ 00:40  loss: 0.5780 - sparse_categorical_accuracy: 0.7100
 2/29 ━━━━━━━━━━━━━━━━ 01:20  loss: 0.5760 - sparse_categorical_accuracy: 0.7120
...
29/29 ━━━━━━━━━━━━━━━━ 19:20  loss: 0.5400 - sparse_categorical_accuracy: 0.7400

Epoch 3 completed in 19:30
 - loss: 0.5400
 - sparse_categorical_accuracy: 0.7400
 - val_loss: 0.5250
 - val_sparse_categorical_accuracy: 0.7350

Training completed in ~58:30
Final metrics on test set:
 - Test loss: 0.5250
 - Test sparse_categorical_accuracy: 0.7350

Model is ready for predictions.

